{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Bibliotecas\n",
    "import cv2\n",
    "import vlc\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#Inicializando Variables\n",
    "\n",
    "model = load_model('modeloMejorado.h5')\n",
    "p = vlc.MediaPlayer(\"wakeup.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Abre el archivo del modelo\n",
    "f = h5py.File(\"modeloMejorado.h5\", mode=\"r+\")\n",
    "model_config_string = f.attrs.get(\"model_config\")\n",
    "\n",
    "# Elimina el argumento 'groups' si está presente\n",
    "if model_config_string.find('\"groups\": 1,') != -1:\n",
    "    model_config_string = model_config_string.replace('\"groups\": 1,', '')\n",
    "    f.attrs.modify('model_config', model_config_string)\n",
    "    f.flush()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m imagen_normalizada\n\u001b[0;32m     80\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m):\n\u001b[0;32m     83\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDurmiendo : \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlist\u001b[39m(prediction)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m3\u001b[39m)),(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mint\u001b[39m(height\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.08\u001b[39m)), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     84\u001b[0m     contador\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Inicializando Variables\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Cargar el clasificador de ojos izquierdo\n",
    "eyeLeft = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lefteye_2splits.xml')\n",
    "eyeRight = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_righteye_2splits.xml')\n",
    "# Verificar que los clasificadores se hayan cargado correctamente\n",
    "if eyeLeft.empty():\n",
    "    print(\"Error al cargar el clasificador de ojos izquierdos.\")\n",
    "if eyeRight.empty():\n",
    "    print(\"Error al cargar el clasificador de ojos derechos.\")\n",
    "\n",
    "# Cargar el modelo\n",
    "model = load_model('modeloMejorado.h5')\n",
    "p = vlc.MediaPlayer(\"wakeup.mp3\")\n",
    "\n",
    "# Variables para almacenar coordenadas de los ojos\n",
    "left_x, left_y, left_w, left_h = 0, 0, 0, 0\n",
    "right_x, right_y, right_w, right_h = 0, 0, 0, 0\n",
    "contador = 0\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "music_playing = False\n",
    "cv2.namedWindow('video', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('video', 800, 720)\n",
    "#Ejecutando Video\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    height,width = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Mostrando Contador\n",
    "    cv2.rectangle(frame, (0, 0), (width, int(height*0.1)), (0,0,0), -1)\n",
    "    cv2.putText(frame,'Contador: '+str(contador),(int(width*0.65), int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "    \n",
    "    #Identificando el Ojo Derecho\n",
    "    ojo_der = eyeRight.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.15,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in ojo_der:\n",
    "        #cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        right_x, right_y, right_w, right_h = x, y, w, h\n",
    "        break\n",
    "    \n",
    "    #Identificando el Ojo Izquierdo\n",
    "    ojo_izq = eyeLeft.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.15,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in ojo_izq:\n",
    "        #cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        left_x, left_y, left_w, left_h = x, y, w, h\n",
    "        break\n",
    "    \n",
    "    #Identificando Coordenadas x,y iniciales y finales para extraer la foto de los ojos\n",
    "    if (left_x > right_x):\n",
    "        start_x, end_x = right_x, (left_x+left_w)\n",
    "    else: \n",
    "        start_x, end_x = left_x, (right_x+right_w)\n",
    "\n",
    "    if (left_y > right_y):\n",
    "        start_y, end_y = right_y, (left_y+left_h)\n",
    "    else:\n",
    "        start_y, end_y = left_y, (right_y+right_h)\n",
    "    \n",
    "    \n",
    "    #Algoritmo de deteccion de sueño\n",
    "    if ((end_x-start_x)>120 and (end_y-start_y)<200):\n",
    "        start_x, start_y, end_x, end_y = start_x-30, start_y-50, end_x+30, end_y+50\n",
    "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "        img = frame[start_y:end_y, start_x:end_x]\n",
    "        imagen = cv2.resize(img, (224, 224))\n",
    "        imagen_normalizada = (imagen.astype(np.float32) / 127.0) - 1\n",
    "        data[0] = imagen_normalizada\n",
    "        prediction = model.predict(data)\n",
    "        \n",
    "        if (list(prediction)[0][1]>=0.95):\n",
    "            cv2.putText(frame,'Durmiendo : '+str(round(list(prediction)[0][1],3)),(10, int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "            contador+=1\n",
    "            if not music_playing and contador >= 15:\n",
    "                music_playing = True\n",
    "                p.play()\n",
    "        \n",
    "        if (list(prediction)[0][0]>=0.95):\n",
    "            cv2.putText(frame,'Despierto',(10, int(height*0.08)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2)\n",
    "            contador-=1\n",
    "            if music_playing:  # Apaga la música si está sonando\n",
    "                music_playing = False\n",
    "                p.stop()\n",
    "                \n",
    "        contador = max(0, min(contador, 15))\n",
    "            \n",
    "    #Mostrar el video de la webcam\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "    #Tecla de salida - acaba la transmisión\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
